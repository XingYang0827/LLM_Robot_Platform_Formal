Below is an instruction that describes a task. Write Python code, using only the APIs provided below, that appropriately completes the request. Provided after the APIs is context about the room's layout and the robot's position.
{
###LLMRobot API: Below are all the classes in a package called "LLMSystem"
{
###Robot API: Below are all the functions that control a robot from a class called "CreateRobot".
{
drive_distance(float32 meters, float32 speed): Drives robot straight the specified distance and then stops.
	Argument 1: Meters the robot should travel. Positive for forwards and negative for backwards motion.
	Argument 2: Speed from 1 to 10
rotate_angle(float32 degrees, float32 rotation_speed): Rotates robot in place from current heading.
	Argument 1: Degrees to turn robot. Negative angle to turn left/counterclockwise. Positive angle to turn right/clockwise.
	Argument 2: The speed at which the robot will rotate (any real number in the range of 1 to 10).
navigate_to_position(float32 xp, float32 yp): The robot will go to the (x,y) position specified.
	Argument 1: The x-position of the desired final location.
	Argument 2: The y-position of the desired final location.
face_coordinate(float32 xp, float32 yp): The robot will turn to face the coordinate specified. Use to take images and scan positions.
	Argument 1: The x-position desired to face towards.
	Argument 2: The y-position desired to face towards.
}

###Image Processing API: Below are all the functions that perform image processing from a class called "ImageProcessing".
{
get_color_image(): Takes and saves an RGB image of the scene in front of a robot in a file called "cameraImage.jpg".
findObject(string obj): Searches for a specified object class in "cameraImage.jpg". The image must be taken prior to calling this function. Returns true if the object class is detected, false otherwise.
	Argument 1: The name of the object class. This function can search for the following object classes: “bottle”, “TV”, “bowl”, “book”, "person"
objectCounts(): Returns a dictionary listing all the objects detected in front of the robot as keys and the amount of them as values.
depthToObject(string obj): Returns how far away in meters the object is from the robot.
	Argument 1: The name of the object class. This function can recognize the following object classes: “bottle”, “TV”, “bowl”, “book”, "person"
}
}

###Position Contextualization
{
The room is a 8x8 square. Navigate to the first coordinate listed for each object. Then call the face_coordinate function to face the rest of the coordinates specified to scan the object.
Coordinates of objects:
{
Jeff's desk: {(3,0). (4,0), and (4,1)}
Bobs's desk: {(2,4). (2,5), and (3,5)}
}
}
}

###Instruction:
{Write Python Code to make the robot <USER TASK>}
